{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## NLP"
      ],
      "metadata": {
        "id": "4EwD6xD-3GRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing (NLP) is the technology used to help machines to understand and learn text and language. With NLP data scientists aim to teach machines to understand what is said and written to make sense of the human language. It is used to apply machine learning algorithms to text and speech.\n",
        "\n"
      ],
      "metadata": {
        "id": "gngjpi701nlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are the techniques used in NLP?"
      ],
      "metadata": {
        "id": "OS3m-UB936Eh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP has primarily two aspects: natural language understanding (NLU) or natural language interpretation (NLI) (i.e. human to machine) and natural language generation (NLG) (i.e. machine to human). In simple words, one can say that NLG is inverse of NLU (broadly called as NLP). Natural language generation (NLG) is when software automatically transforms data into written narrative.\n",
        "\n"
      ],
      "metadata": {
        "id": "GOdCnSf63Eov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SYNTACTIC & SEMANTIC ANALYSIS\n",
        "Natural Language Processing tasks are primarily achieved by syntactic analysis and semantic analysis. There are many process involves in this process like:\n",
        "\n",
        "- Named entity recognition (NER) — determine the parts of a text that can be identified and categorized into preset groups, like names of people and objects.\n",
        "- Word sense disambiguation — give meaning to words based on their context\n",
        "- Natural language generation (NLG):— It involves using databases to derive semantic intentions and convert them into human language."
      ],
      "metadata": {
        "id": "na9hVR4Z7u1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Programming\n",
        "\n",
        "In python, we have several libraries to work with text.\n",
        "\n",
        "- Scikit-learn, Keras, TensorFlow — has some text processing capabilities\n",
        "- NLTK — Natural language toolkit.\n",
        "- SpaCy — is an industrial strength NLP package with many practical tools in a nice API.\n",
        "\n",
        "Other libraries — TextBlob, gensim, Stanford CoreNLP, OpenNLP"
      ],
      "metadata": {
        "id": "ICuUpdev8shb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Types:\n",
        "- Pattern based (like we find pattern of characters or strings to match)\n",
        "- AI based (we use DL, seq2seq or transformers) to see the context of language"
      ],
      "metadata": {
        "id": "9lbnM8TgHGdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understand vocabulary"
      ],
      "metadata": {
        "id": "-VQOsftpLKPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## One simple to process our english language is BOW\n",
        "\n",
        "from collections import Counter\n",
        "s = \"My name is hamsof, and meaning of hamsof is ...\"\n",
        "token_counter = Counter(s.split())\n",
        "\n",
        "token_counter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMwkvbzsLVWt",
        "outputId": "00583faa-e154-46ee-b65d-b059a6c1e3a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'My': 1,\n",
              "         'name': 1,\n",
              "         'is': 2,\n",
              "         'hamsof,': 1,\n",
              "         'and': 1,\n",
              "         'meaning': 1,\n",
              "         'of': 1,\n",
              "         'hamsof': 1,\n",
              "         '...': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see there are many issues here like it is capturing hamsof and hamsof, differently, lets resolve it"
      ],
      "metadata": {
        "id": "Z0YwoJ2fMfyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets now talk about punctuation, stop words"
      ],
      "metadata": {
        "id": "B0ZP_PUKNKZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regular expressions are a way to improve vocabulary by spliting not only ' ' white spaces but also on ? or signs like stop. "
      ],
      "metadata": {
        "id": "pEJWwQsbPW1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = re.compile(r\"([-\\s.,;!?])+\")\n",
        "sentence = \"Natural Language Processing is so awesome, isn't it?\"\n",
        "tokens = pattern.split(sentence)\n",
        "tokens = [token for token in tokens if token not in '-\\t\\n.,;!?']\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOc4Ia81Nulx",
        "outputId": "6dbb6fcd-c444-4458-fb26-3bc1474738e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " ' ',\n",
              " 'Language',\n",
              " ' ',\n",
              " 'Processing',\n",
              " ' ',\n",
              " 'is',\n",
              " ' ',\n",
              " 'so',\n",
              " ' ',\n",
              " 'awesome',\n",
              " ' ',\n",
              " \"isn't\",\n",
              " ' ',\n",
              " 'it']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But Regrex takes too much complexity to code to tokenize our sentence, lets move to some built in functionality"
      ],
      "metadata": {
        "id": "sHfrzqWYPtf4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qfmBn_WTQCB8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}